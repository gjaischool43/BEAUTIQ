import os, io, json, datetime, re, logging
from collections import Counter
from typing import List, Literal, Dict, Any

import pandas as pd
from fastapi import FastAPI, UploadFile, File, Form, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, EmailStr, constr
from starlette.concurrency import run_in_threadpool

import os, logging
from typing import Literal, Optional, TypeAlias
from fastapi import FastAPI, HTTPException

from sqlalchemy import text
import bcrypt

from db_digest import engine  # ê¸°ì¡´ì— ì‚¬ìš© ì¤‘ì¸ SQLAlchemy engine ì¬ì‚¬ìš©

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ OpenAI: lazy client â”€â”€â”€â”€â”€â”€â”€â”€â”€
from openai import OpenAI

import os
from sqlalchemy import create_engine

DB_URL = os.getenv("DATABASE_URL")
if not DB_URL:
    raise RuntimeError("DATABASE_URL is not set")

engine = create_engine(DB_URL, pool_pre_ping=True)

ShortStr: TypeAlias = constr(min_length=1, max_length=200)
LongStr: TypeAlias = constr(min_length=1, max_length=5000)
_client = None



def get_openai_client() -> OpenAI:
    global _client
    if _client is None:
        # í™˜ê²½ë³€ìˆ˜ ì—†ë”ë¼ë„ í•˜ë“œì½”ë“œ í‚¤ê°€ ìˆìœ¼ë©´ ìƒì„±
        key = os.getenv("OPENAI_API_KEY") or OPENAI_API_KEY
        if not key:
            raise RuntimeError("OPENAI_API_KEYê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤.")
        _client = OpenAI(api_key=key)
    return _client

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ ìœ í‹¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€
def _tier(s: float) -> str:
    s = float(s)
    return "S" if s >= 0.85 else "A" if s >= 0.75 else "B" if s >= 0.60 else "C"

def md_table_from_rows(rows: List[List[Any]]) -> str:
    if not rows or not rows[0]:
        return ""
    head = "| " + " | ".join(map(str, rows[0])) + " |\n"
    sep  = "| " + " | ".join(["---"]*len(rows[0])) + " |\n"
    body = "".join("| " + " | ".join(map(str, r)) + " |\n" for r in rows[1:])
    return head + sep + body

def crop(s: str, n: int) -> str:
    s = s or ""
    return s if len(s) <= n else s[:n]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ LLM ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€
PRIMARY_MODEL   = os.getenv("PRIMARY_MODEL", "gpt-5-mini")
FALLBACK_MODELS = [PRIMARY_MODEL, os.getenv("FALLBACK_MODEL_1", "gpt-4o-mini")]
MAX_TOK_SECTION = int(os.getenv("MAX_TOK_SECTION", "1500"))
MIN_ACCEPT_CHARS= int(os.getenv("MIN_ACCEPT_CHARS", "250"))

def llm_section(prompt: str, max_tok=MAX_TOK_SECTION, tries=3) -> str:
    base = prompt.strip()
    for m in FALLBACK_MODELS:
        p = base
        mtok = max_tok
        for i in range(tries):
            try:
                client = get_openai_client()
                resp = client.chat.completions.create(
                    model=m,
                    messages=[
                        {"role":"system","content":"ë„ˆëŠ” í•œêµ­ì–´ BM ë¦¬í¬íŠ¸ ì „ë¬¸ê°€ë‹¤. ë°˜ë“œì‹œ 'ë§ˆí¬ë‹¤ìš´ í…ìŠ¤íŠ¸'ë§Œ ì¶œë ¥í•œë‹¤. ì½”ë“œë¸”ë¡/ì„¤ëª…ë¬¸ ê¸ˆì§€. ê³¼ì¥ ê¸ˆì§€. í‘œ/ë¦¬ìŠ¤íŠ¸ ì ê·¹ ì‚¬ìš©."},
                        {"role":"user","content":p}
                    ],
                    # ìµœì‹  ìŠ¤í™: max_tokens ëŒ€ì‹  max_completion_tokens ì‚¬ìš©
                    max_completion_tokens=mtok,
                )
                txt = (resp.choices[0].message.content or "").strip()
                if len(txt) >= MIN_ACCEPT_CHARS:
                    return txt
            except Exception as e:
                logging.warning(f"[LLM WARN] model={m} try={i+1}: {e}")
            # ì‹¤íŒ¨ ì‹œ ìš”ì•½í˜• + í† í° ì¶•ì†Œ
            p = "ì•„ë˜ ì§€ì‹œë¥¼ ìš”ì•½í˜•ìœ¼ë¡œ, í‘œ/ë¦¬ìŠ¤íŠ¸ ì¤‘ì‹¬ìœ¼ë¡œ, êµ°ë”ë”ê¸° ì—†ì´ ì‘ì„±í•˜ë¼.\n\n" + crop(base, 3500)
            mtok = max(900, int(mtok * 0.8))
    return "> [LLM ì‘ë‹µ ë¶€ì¡±ìœ¼ë¡œ ì„¹ì…˜ ìƒì„±ì„ ê±´ë„ˆëœ€]"

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ ìš”ì•½/í†µê³„ â”€â”€â”€â”€â”€â”€â”€â”€â”€
def make_digest(df: pd.DataFrame, topn=15) -> dict:
    d: Dict[str, Any] = {}
    s = df["score"].astype(float)
    if len(s):
        d["score_stats"] = {
            "min": float(s.min()), "p10": float(s.quantile(0.10)),
            "p25": float(s.quantile(0.25)), "p50": float(s.quantile(0.50)),
            "p75": float(s.quantile(0.75)), "p90": float(s.quantile(0.90)),
            "max": float(s.max()), "mean": float(s.mean()),
            "std": float(s.std(ddof=0)), "rows": int(len(s)),
        }
    else:
        d["score_stats"] = {"rows": 0}
    d["tier_counts"] = {
        "S": int((df["score"]>=0.85).sum()),
        "A": int(((df["score"]>=0.75)&(df["score"]<0.85)).sum()),
        "B": int(((df["score"]>=0.60)&(df["score"]<0.75)).sum()),
        "C": int((df["score"]<0.60).sum()),
    }
    c = Counter()
    for s_ in df["key_ings"].fillna(""):
        for t in re.split(r"[,\|/;]", str(s_)):
            t = t.strip()
            if t:
                c[t]+=1
    d["top_key_ings"] = [{"token":k,"cnt":v} for k,v in c.most_common(topn)]

    cols = [c for c in ["product_id","product_name","score","key_ings","summary3"] if c in df.columns]
    top = (df.sort_values("score", ascending=False).head(max(10, topn))[cols]).fillna("")
    rows = [["product_id","name","score","tier","key_ings","insight"]]
    for _, r in top.iterrows():
        rows.append([
            str(r.get("product_id","")),
            str(r.get("product_name","")),
            f'{float(r.get("score",0.0)):.3f}',
            _tier(r.get("score",0.0)),
            str(r.get("key_ings","")),
            (str(r.get("summary3",""))[:160] + "â€¦") if len(str(r.get("summary3",""))) > 160 else str(r.get("summary3","")),
        ])
    d["top_products_table"] = rows
    d["top_products_table_md"] = md_table_from_rows(rows)
    return d

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ í”„ë¡¬í”„íŠ¸ ìƒì„± â”€â”€â”€â”€â”€â”€â”€â”€â”€
def make_prompts(digest_brief: str, top_table_md: str,
                 influencer: str, category: str, concept: str, channel_url: str):
    def P(title, body): return body.strip()
    p1 = f"""
ì œëª©: "# 1) ë¸Œëœë“œ ìš”ì•½ (Brand Summary)"
í•„ìˆ˜ í•­ëª©(ê° 1~2ì¤„):
- ë¸Œëœë“œëª… (ê°€ì¹­)
- ìŠ¬ë¡œê±´ / ì½˜ì…‰íŠ¸ ë¬¸êµ¬
- í•µì‹¬ í•œ ì¤„ ì •ì˜
- ì œì•ˆ ë°°ê²½ ìš”ì•½(ë°ì´í„° ìˆ˜ì¹˜ 1~2ê°œ)
ë§¥ë½: ì¸í”Œë£¨ì–¸ì„œ={influencer}, ì¹´í…Œê³ ë¦¬={category}, ì½˜ì…‰íŠ¸={concept}
[ë°ì´í„° ìš”ì•½]
{digest_brief}
[ìƒìœ„ ì œí’ˆ í…Œì´ë¸”(ì°¸ê³ )]
{top_table_md}
"""
    p2 = f"""
ì œëª©: "# 2) í¬ë¦¬ì—ì´í„° ë¶„ì„ (Creator Analysis)"
í¬í•¨:
- ì±„ë„ ì •ë³´ (YouTube, ë§í¬={channel_url} í‘œê¸°; ìˆ˜ì¹˜ ì¶”ì • ê¸ˆì§€)
- ì£¼ìš” ì¹´í…Œê³ ë¦¬ (key_ings/summary3 ë‹¨ì„œ ê¸°ë°˜)
- ê°ì„± í†¤ & ì–¸ì–´ íŒ¨í„´
- íŒ¬ ë°˜ì‘(ê¸/ë¶€ ë‰˜ì•™ìŠ¤)
- ê°•ì /ì°¨ë³„ì 
[ë°ì´í„° ìš”ì•½]
{digest_brief}
[ìƒìœ„ ì œí’ˆ í…Œì´ë¸”(ì°¸ê³ )]
{top_table_md}
"""
    p3 = f"""
ì œëª©: "# 3) ì‹œì¥ ë¶„ì„ (Market Landscape)"
í¬í•¨:
- ì¹´í…Œê³ ë¦¬ ì •ì˜/ê¸°íšŒ(2~3ë¬¸ë‹¨)
- ê²½ìŸ í¬ì§€ì…˜ í‘œ(ë¸Œëœë“œ|í•µì‹¬ì„±ë¶„/ì†ì„±|ì¶”ì • í¬ì§€ì…˜) â€” CSV ê´€ì°° ê¸°ë°˜, 'ì¶”ì •' ëª…ì‹œ
- ê°€ê²©/ì„±ë¶„/í¬ì§€ì…”ë‹ ì„œìˆ 
- ë¦¬ë·° ì¸ì‚¬ì´íŠ¸(4~6)
- ê³µë°± ë‹ˆì¦ˆ(3~5)
[ë°ì´í„° ìš”ì•½]
{digest_brief}
"""
    p4 = f"""
ì œëª©: "# 4) ë¸Œëœë“œ ì½˜ì…‰íŠ¸ ì œì•ˆ (Concept Proposal)"
í¬í•¨:
- í•µì‹¬ ì½˜ì…‰íŠ¸(1ë¬¸ë‹¨)
- í•µì‹¬ ì†ì„±(5~8)
- í†¤ì•¤ë§¤ë„ˆ(4~6)
- ë¹„ì£¼ì–¼ ì½˜ì…‰íŠ¸(3~5ì¤„)
- íƒ€ê¹ƒ(1ë¬¸ë‹¨)
[ë°ì´í„° ìš”ì•½]
{digest_brief}
"""
    p5 = f"""
ì œëª©: "# 5) ì œí’ˆ ì œì•ˆ (Product Proposal)"
ìš”êµ¬: í‘œ 1ê°œ + ë¶ˆë¦¿
- í‘œ: ì œí’ˆëª…|ì£¼ìš” ì„±ë¶„|ì œí˜•|ì°¨ë³„ í¬ì¸íŠ¸|ì†Œë¹„ì ë¬¸ì¥ (â‰¤3í–‰)
- ë¶ˆë¦¿: íƒ€ê¹ƒ/ì‚¬ìš©ìƒí™©/ë¦¬ìŠ¤í¬(3~6ê°œ)
[ë°ì´í„° ìš”ì•½]
{digest_brief}
"""
    p6 = f"""
ì œëª©: "# 6) íƒ€ê¹ƒ ì„¸ê·¸ë¨¼íŠ¸ ë° í¬ì§€ì…”ë‹ (Segmentation & Positioning)"
í¬í•¨:
- íƒ€ê¹ƒ ì„¸ê·¸ë¨¼íŠ¸(4~6ì¤„)
- í˜ë¥´ì†Œë‚˜(5~8)
- STP ìš”ì•½í‘œ(3í–‰)
- í¬ì§€ì…”ë‹ ë§µ ì„œìˆ (1ë¬¸ë‹¨)
[ë°ì´í„° ìš”ì•½]
{digest_brief}
"""
    p7 = f"""
ì œëª©: "# 7) ë¸Œëœë”© ì „ëµ (Brand Strategy)"
í¬í•¨:
- ìŠ¤í† ë¦¬ë¼ì¸(1ë¬¸ë‹¨)
- í†¤ì•¤ë§¤ë„ˆ ê°€ì´ë“œ(6~10)
- ë¡œê³ /ì»¬ëŸ¬ ë°©í–¥(4~6)
- ì½˜í…ì¸  ìŠ¤íƒ€ì¼(6~10)
[ë°ì´í„° ìš”ì•½]
{digest_brief}
"""
    p8 = f"""
ì œëª©: "# 8) ìœ í†µ ë° ì±„ë„ ì „ëµ (Channel Strategy)"
í¬í•¨:
- 1ì°¨ ì±„ë„(5~8)
- 2ì°¨ ì±„ë„(5~8)
- ëŸ°ì¹­ ìº í˜ì¸ í”Œë¡œìš° í‘œ(ë‹¨ê³„|í•µì‹¬ì•¡ì…˜|ì„±ê³¼ì§€í‘œ)
- íŒë§¤/KPI í‘œ(metric|target|how_to_measure 6~10í–‰)
[ë°ì´í„° ìš”ì•½]
{digest_brief}
"""
    p9 = f"""
ì œëª©: "# 9) ì¬ë¬´ / ì‹œë®¬ë ˆì´ì…˜ (Financial & Simulation)"
í¬í•¨:
- ì›ê°€/ë§ˆì§„/ëª©í‘œ íŒë§¤(í‘œ: sku|assumption|notes â€” 'ê°€ì •' ëª…ì‹œ)
- ì±„ë„ë³„ ROI(í‘œ)
- ì„±ì¥ ì‹œë‚˜ë¦¬ì˜¤(1ë…„/3ë…„)
- ë¦¬ìŠ¤í¬/ëŒ€ì‘(í‘œ 6~10í–‰)
[ë°ì´í„° ìš”ì•½]
{digest_brief}
"""
    p10 = f"""
ì œëª©: "# 10) ê²°ë¡  ë° ì œì•ˆ ìš”ì•½ (Conclusion & Next Step)"
í¬í•¨:
- í•µì‹¬ ìš”ì•½(3ì¤„)
- ì œì•ˆ ê°€ì¹˜(3~5ì¤„)
- ë‹¤ìŒ ë‹¨ê³„(5~8)
[ë°ì´í„° ìš”ì•½]
{digest_brief}
"""
    pA = f"""
ì œëª©: "# ğŸ“ ë¶€ë¡ (Appendix)"
í¬í•¨(ìˆœì„œ ê³ ì •):
1) ê°ì„± ë¶„ì„ ìš”ì•½(5~8)
2) TF-IDF ìƒìœ„ í‚¤ì›Œë“œ í‘œ(rank|token|note â€” ì •ì„± ë©”ëª¨)
3) ê²½ìŸì œí’ˆ ë¶„ì„í‘œ(brand|í•µì‹¬ì„±ë¶„/ì†ì„±|ë©”ì‹œì§€ í†¤|ë¹„ê³  â€” 'ì¶”ì •' ëª…ì‹œ)
4) ìƒìœ„ ì œí’ˆ ìš”ì•½í‘œ(ì›ë¬¸ í‘œ ì¬ì²¨ë¶€)
[ë°ì´í„° ìš”ì•½]
{digest_brief}
[ìƒìœ„ ì œí’ˆ í…Œì´ë¸”(ì›ë¬¸)]
{top_table_md}
"""
    return [
        ("1) ë¸Œëœë“œ ìš”ì•½", p1),
        ("2) í¬ë¦¬ì—ì´í„° ë¶„ì„", p2),
        ("3) ì‹œì¥ ë¶„ì„", p3),
        ("4) ë¸Œëœë“œ ì½˜ì…‰íŠ¸ ì œì•ˆ", p4),
        ("5) ì œí’ˆ ì œì•ˆ", p5),
        ("6) íƒ€ê¹ƒ ì„¸ê·¸ë¨¼íŠ¸ ë° í¬ì§€ì…”ë‹", p6),
        ("7) ë¸Œëœë”© ì „ëµ", p7),
        ("8) ìœ í†µ ë° ì±„ë„ ì „ëµ", p8),
        ("9) ì¬ë¬´ / ì‹œë®¬ë ˆì´ì…˜", p9),
        ("10) ê²°ë¡  ë° ì œì•ˆ ìš”ì•½", p10),
        ("ë¶€ë¡", pA),
    ]

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ Pydantic ìŠ¤í‚¤ë§ˆ â”€â”€â”€â”€â”€â”€â”€â”€â”€
class CSVRecords(BaseModel):
    type: Literal["records"] = "records"
    columns: List[str]
    rows: List[List[object]]


class BuildReportInput(BaseModel):
    influencer: str
    category: str
    concept: str
    channel_url: str
    topn_ings: int = 15
    csv: CSVRecords

class Section(BaseModel):
    title: str
    format: str = "md"
    content: str

class BuildReportOutput(BaseModel):
    meta: Dict[str, Any]
    digest: Dict[str, Any]
    sections: List[Section]

# --- Pydantic ëª¨ë¸ ---
class RequestCreate(BaseModel):
    activity_name: ShortStr
    platform: Literal['youtube','instagram','tiktok','x','etc']
    channel_name: ShortStr
    category_code: Literal['skin_toner','essence_serum_ampoule','lotion','cream','mist_oil']
    brand_concept: LongStr
    contact_method: constr(min_length=1, max_length=120)
    email: EmailStr
    view_pw: constr(min_length=4, max_length=128)

class RequestCreateResp(BaseModel):
    request_id: int
    message: str

# â”€â”€â”€â”€â”€â”€â”€â”€â”€ í•µì‹¬ ë¡œì§ â”€â”€â”€â”€â”€â”€â”€â”€â”€
def build_report_from_df(df: pd.DataFrame, influencer: str, category: str, concept: str,
                         channel_url: str, topn_ings: int) -> BuildReportOutput:
    for c in ["product_id","product_name","key_ings","summary3"]:
        if c not in df.columns:
            df[c] = ""
        df[c] = df[c].astype(str)

    if "score" not in df.columns:
        raise ValueError("CSVì— score ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. (í•„ìˆ˜)")

    df["score"] = pd.to_numeric(df["score"], errors="coerce").fillna(0.0)

    digest = make_digest(df, topn=topn_ings)
    digest_brief = json.dumps({
        "score_stats": digest.get("score_stats", {}),
        "tier_counts": digest.get("tier_counts", {}),
        "top_key_ings": (digest.get("top_key_ings", [])[:12]),
    }, ensure_ascii=False, indent=2)
    digest_brief = crop(digest_brief, 3000)
    top_table_md = crop(digest.get("top_products_table_md", ""), 2500)

    prompts = make_prompts(
        digest_brief, top_table_md,
        influencer=influencer, category=category,
        concept=concept, channel_url=channel_url
    )

    sections_md: List[Section] = []
    for label, pr in prompts:
        sections_md.append(Section(title=label, content=llm_section(pr)))

    ts = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    return BuildReportOutput(
        meta={
            "influencer": influencer,
            "category": category,
            "concept": concept,
            "channel_url": channel_url,
            "created_at": ts
        },
        digest={
            "score_stats": digest.get("score_stats", {}),
            "tier_counts": digest.get("tier_counts", {}),
            "top_key_ings": digest.get("top_key_ings", [])[:12],
            "top_products_table_md": top_table_md
        },
        sections=sections_md
    )
